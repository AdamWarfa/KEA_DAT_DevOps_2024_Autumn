<!DOCTYPE html>
<html>
<head>
    <style>
        
body {
    font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
    background-color: #1e1e1e; /* Dark background for the body */
    margin: 0;
    padding: 0;
    overflow: hidden;
}

/* Full-Width Slideshow Container */
#slideshow {
    width: 100%;
    height: 100vh;
    position: relative;
}

/* Full-Width and Dark Mode Slide Styles */
.remark-slide-content {
    color: #ddd; /* Light text color for readability */
    background-color: #13151a; /* Dark background for slides */
    width: 100%;
    height: 100%;
    padding: 40px;
    padding-top: 0px;
    box-sizing: border-box;
}

/* Headers */
.remark-slide-content h1, .remark-slide-content h2 {
    color: rgb(8, 107, 194); /* Bright color for headers */
    margin-top: 5px;
}

.remark-slide-content h1 {
    font-size: 2em;
}

.remark-slide-content h2 {
    font-size: 1.2em;
}

/* Paragraphs */
.remark-slide-content p {
    font-size: 1.1em;
    line-height: 1.5;
}

/* Lists */
.remark-slide-content ul, .remark-slide-content ol {
    margin-left: 20px;
    font-size: 1.2em;
}

/* Images */
.remark-slide-content img {
    max-width: 100%;
    height: auto;
    display: block;
    margin: 20px auto;
}

/* Links */
a:link, a:visited {
    color: green;
}

/* Code */
.remark-slide-content pre {
    background: #333; /* Dark background for code blocks */
    border: 1px solid #444;
    color: #eee; /* Light text for code */
    padding: 8px;
    overflow: auto;
}

.remark-slide-content code {
    font-family: 'Courier New', Courier, monospace;
    background-color: #333;
    padding: 2px 5px;
    color: #eee;
}


table {
    /* center */
    margin-left: auto;
    margin-right: auto;
    border-collapse: collapse; /* This ensures that the border styles are applied uniformly */
}

th {
    color: darkgrey;
}

table, th, td {
    border: 1px solid rgba(255, 255, 255, 0.3); 
}

.title-card {
    display: flex;
    justify-content: center;
    align-items: center;
    text-align: center;
    height: 100vh;
}

.title-card h1 {
    color: cyan;
}

.exercise-card h1 {
    color: green;
}

.fullscreen-video {
    width: 40vw; 
    height: 50vh;
    border: none;
}

    </style>

    <title>01._introduction || 02._build_tools || 03._packaging || 04._virtualization_containerization || 05._docker || 06._dockerfile</title>
</head>
<body>
    <!-- The Remark.js container -->
<textarea id="source" style="display:none;"><div class="title-card">
    <h1>Docker, Continuous Delivery, The Simulation</h1>
</div>


---

# Weekly commit activity

<iframe src="./assets_introduction/commit_activity_weekly.svg" style="height: 50vh; width: 100%;" frameborder="0"></iframe>

---

# Daily commit activity

<iframe src="./assets_introduction/commit_activity_daily.svg" style="height: 50vh; width: 100%;" frameborder="0"></iframe>


---

# Do not leak sensitive information

Don't push the SQLite database file into the repository!

---

# Weekly DevOps pep-talk!

**Automate everything!**



---

<!-- Build tools -->

<div class="title-card">
    <h1>Build tools</h1>
</div>

---

# What build tools do you know?

Discuss in pairs:

*OS level package managers?*

*Package managers for specific programming languages?*

*Other build tools and their build files?*

---

# OS level package managers

* **Windows**: chocolatey

* **MacOs**: homebrew

* **Linux**: apt, yum, dnf, pacman, zypper, portage, rpm, snap, flatpak, nix 
 
---

# Package managers for programming languages

<div>
    <img src="./assets_build_tools/programming_languages.png" alt="Programming Languages Package Managers"/>
</div>

---

# Build tools / Build files

<div>
    <img src="./assets_build_tools/build_files.png" alt="Build Files"/>
</div>


---

# Python Build Tools

I have placed an optional tutorial here [Python Build Tools / Virtual Environments](./assets_build_tools/python_build_tools.md) if you are interested in the different types of ways to create virtual environments in Python.

I really recommend using [poetry](https://python-poetry.org/).




---

<div class="title-card">
    <h1>Packaging</h1>
</div>

---

# Why package?

* **Reusability**: You can reuse your code in other projects.

* **Distribution**: You can distribute your code to others.

* **Versioning**: You can version your code.

* **Dependency management**: You can manage dependencies.

---

# How to distribute code

## As source code

All: `.zip` / `.tar.gz` for instance in GitHub Releases. 

Python: `setup.py` + `requirements.txt`

## As binary code

All: `.exe` / `.dmg` / `.deb` / `.rpm`

Java: `.jar`

C++: `.dll`

## As a container

Docker, Kubernetes, Podman. 

## As a library

Node Modules, Python Packages, Java Libraries.

---

# Examples

<img src="./assets_packaging/packages.png" alt="packages examples types of packages per language">

---

# Services

* **DockerHub**

* **GitHub**: You can distribute your code on via GitHub Packages.
    
<ul style="list-style-type: '+ '"><li>Integrates nicely with your pipelines in GitHub Actions.</li></ul>

* **JFrog Artifactory**: Supports many types of artifact repositories. 

<img src="./assets_packaging/jfrog_logo.png" alt="Jfrog Artifactory logo">


---

# [Semantic versioning](https://semver.org/)

**Major**: MAJOR version when you make incompatible API changes

**Minor**: MINOR version when you add functionality in a backward compatible manner

**Patch**: PATCH version when you make backward compatible bug fixes

Additional labels for pre-release and build metadata are available as extensions to the `MAJOR.MINOR.PATCH` format.





---

<div class="title-card">
    <h1>Virtualization vs. containerization</h1>
</div>

---

# What is virtualization? What can you virtualize?

*What is virtualization?*

*Given a computer, what can you virtualize?*

---

# Virtualization

**Definition**: Virtualization is the process of creating a software-based (or virtual) representation of something rather than a physical one.

**Types**:

1. **Hardware Virtualization**: Virtualization of hardware resources like CPU, memory, and storage.

2. **Software Virtualization**: Virtualization of software resources like operating systems, applications, and networks.

---

# Hypervisor

> A hypervisor or virtual machine monitor (VMM) is *computer software*, *firmware* or *hardware* that creates and runs virtual machines. A computer on which a hypervisor runs one or more virtual machines is called a **host machine**, and each virtual machine is called a **guest machine**.

> This contrasts with **operating-system-level virtualization**, where all instances (usually called containers) must **share a single kernel**, though the guest operating systems can **differ in user space**, such as different Linux distributions with the same kernel.

<img src="./assets_virtualization_containerization/hypervisor.png" alt="hypervisor" style="height: 22vh;">

[Source: Wikipedia - Hypervisor](https://en.wikipedia.org/wiki/Hypervisor)

---

# Containerization

The benefit of containerization is to have multiple applications that share the same kernel. 

Virtual machines require a new OS for each environment. 


| Containers                                                                 | Virtual Machines                                                                |
|----------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| <img src="./assets_virtualization_containerization/containers.png" alt="containers" style="width: 16vw;">  | <img src="./assets_virtualization_containerization/virtual_machines.png" alt="virtual machines" style="width: 16vw;"> |

[Source](https://web.archive.org/web/20201101123422/https://docs.docker.com/get-started/)

[Source 2](https://www.docker.com/resources/what-container/)

---

# Docker's definition of containers

> A Docker container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.

> Containers isolate software from its environment and ensure that it works uniformly despite differences for instance between development and staging.

[Source: Docker Docs](https://www.docker.com/what-container)

---

# Why containerize?

*Can you think of reasons?*

---

# Benefits of containerization


**Faster Project Setup:** Installing a database + surrounding environment with a single command. 

**Portability:** Containers can run on any machine that has Docker installed.

**Reproducibility:** Consistent setup across systems.
  - Solves the "It Works on My Machine" Problem.

**Isolation:** Separate dependencies for each application. 

**Scailability**: Easier to scale individual services.

---

# History of containers

Containers have been around for decades before Docker. 

**1979 - 1982**: [chroot](https://en.wikipedia.org/wiki/Chroot) command in Unix enables users to create environments for processes. 

**1999**: [FreeBSD jail](https://en.wikipedia.org/wiki/FreeBSD_jail) expands on `chroot` to create isolated environments. Containers are still sometimes called jails. 

**2001 - 2008**: Linux VServer, OpenVZ, cgroups (Google) and LXC.

**2013**: The rise of Docker. Written in Go. 

---

# Modern container runtimes

[containerd](https://containerd.io/)

[Podman](https://podman.io/)

[Kata Containers](https://katacontainers.io/)

Docker

---

# Containerization and DevOps

Containers are not DevOps. But they can help you achieve DevOps. 

According to an early real-world case, Dwayne Holmes experienced how containers increase productivity by **abstracting**:

1. **infrastructure**: the dial-tone principal - you pick up the phone and it works without needing to know how it works

2. **specialization**: operations could create containers that developers could use over and over again

3. **automation**: containers can be built over and over again and everything will just work

Source: Holmes, How a Hotel Company Ran $30B of Revenue in Containers (2020)





---

<div class="title-card">
    <h1>Docker</h1>
</div>

---

# Docker terminology?

**Image**

**Container**

**Volume**

**Networking**

*Can you give informal definitions for these?*

---

# Docker terminology (informal)

**Image**: Blueprint / Recipe

**Container**: The instance of the image

**Volume**: Holds the data of the containers

**Networking**: Enables the pieces to speak


---

# Basic CLI example

Run the [hello-world container](https://hub.docker.com/_/hello-world/) from DockerHub and delete it after its execution:

```bash
$ docker run --rm hello-world
```

---

# Overview with Redis example

[https://hub.docker.com/_/redis/](Redis is a popular key-value store). 

*Can you explain the following commands?*

```bash
$ docker pull redis
$ docker run redis
```

Run in detached mode:

```bash
$ docker run -d redis
$ docker ps
$ docker stop <container-id>
```

---

# Alpine Linux

[Alpine Linux](https://en.wikipedia.org/wiki/Alpine_Linux) is a very lightweight Linux distribution.

Get an interactive [Alpine Linux](https://hub.docker.com/_/alpine/) shell:

```bash
$ docker run -it --rm alpine /bin/sh
```

`-it` is short for `i` = `--interactive` and `t` = `--tty` (Pseudo-TTY).

**Note**: Windows users might need to prefix the `docker run` with `winpty`.

Go back to the local terminal by typing `exit` in the container shell.

```bash
/ # exit
```

---

<div class="title-card">
    <h1>Volumes</h1>
</div>

---

# Volumes

You can mount directories (volumes) from your host to a container using the `-v` flag.

1. Create a directory with a file in it locally:

    ```bash
    $ mkdir mydockerdata
    $ echo 'Hello from the host!' > ./mydockerdata/mountedfile.txt
    ```

2. Run an Alpine container and mount the directory:

    ```bash
    $ docker run -it -v ./mydockerdata:/data alpine:latest /bin/sh
    ```

*Where can I find the file?*


---

# Volumes - II

*What happens if you delete the `mydockerdata` folder locally?* 

*Let's try it*. First delete the folder locally.


1. Find the container ID:

    ```bash
    $ docker ps -a
    ```

2. Start the container and attach it to interact with it:

    ```bash
    $ docker start <CONTAINER_ID>
    $ docker attach <CONTAINER_ID>
    ```

In the container run:

```bash
$ cat /data/mountedfile.txt
```

---

# Create a volume for data

Create a volume:

```bash
$ docker volume create test-volume
```

Use the volume in a container:

```bash
$ docker run -it --rm -v test-volume:/mydata alpine /bin/sh
```

In the Alpine shell add a file to the `mydata` directory:

```bash
/ # echo 'Hello from the volume!' > /mydata/volume.txt
```

---

# Check out the content of the volume

The best way to interact with the volume is through the container. 

You could run Docker with elevated privileges to access the volume directly, but it's not recommended.

```bash
$ docker volume inspect test-volume
```

In Docker Desktop, choose volumes and choose `test-volume` to see the content.

<img src="./assets_docker/volume_docker_desktop.png" alt="volume docker desktop">


---

# Why volumes?

*Can you give examples of what you would want to mount in a Docker container?*

---

# Volumes: That's why!

Database data:

```bash
$ docker run -d -v /my/local/data:/var/lib/mysql mysql:latest
```

Configuration files:

```bash
$ docker run -d -v /my/local/nginx.conf:/etc/nginx/nginx.conf nginx:latest
```

Sharing data between containers:

```bash
$ docker run -d -v /my/local/data:/shared/data webserver:latest
$ docker run -d -v /my/local/data:/shared/data worker:latest
```

Source code, persistent storage for applications (fx. CMS), storing log files, SSL certificates, backup local data in a container etc.

---

<div class="title-card">
    <h1>Docker Networking</h1>
</div>

---

# Docker Networking

Let's explore networks in Docker by creating a network and then have two containers join it.

Create a network:

```bash
$ docker network create mynetwork
```

Run two named containers on the `mynetwork` network:

```bash
$ docker run -dit --name container1 --network mynetwork alpine:latest
$ docker run -dit --name container2 --network mynetwork alpine:latest
```

`-d`: Runs the container in detached mode (in the background).

`-i`: Keeps STDIN open even if not attached (interactive mode).

`-t`: Allocates a pseudo-TTY (a terminal interface).

---

# Verify networking between the containers

Access `container1` by attaching it:

```bash
$ docker attach container1
```
From `container1` ping `container2` (with example response):

```bash
/ # ping container2
PING container2 (172.18.0.3): 56 data bytes
64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.075 ms
...
...
```

After a while stop the ping by pressing `Ctrl+C`.

If you see no packet loss, the containers are connected. Example:

```txt
--- container2 ping statistics ---
37 packets transmitted, 37 packets received, 0% packet loss
round-trip min/avg/max = 0.110/0.225/0.566 ms
```

---

# Expose ports to the host

Run an Nginx Container:

```bash
$ docker run -dit --name webserver --network mynetwork -p 8080:80 nginx:latest
```

Check out `http://localhost:8080` in a browser.

In `container2` request the webserver on the same network (install CURL first):

```bash
/ # apk add curl
/ # curl http://webserver
```

Inspect the network to see which containers are connected and their IP addresses. 

```bash
$ docker network inspect mynetwork
```

---

# Clean up!

```bash
$ docker stop container1 container2 webserver
$ docker rm container1 container2 webserver
$ docker network rm mynetwork
```



---

<div class="title-card">
    <h1>The Dockerfile</h1>
</div>

---

# Dockerfile Python example 

<img src="./assets_dockerfile/dockerfile.png" alt="dockerfile">


```Dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

# Copy all files from current directory to /usr/src/app in container
COPY . .

CMD ["python", "app.py"]
```

*Can you explain each line?*

---

# Dockerfile Node.js example 

```Dockerfile
FROM node

WORKDIR /usr/src/app

COPY package*.json ./

RUN npm install

COPY . .

EXPOSE 8080
CMD [ "npm", "start" ]
```

*Can you explain each line?*

---

# Two ways to start

*What is the difference between these two?*

```Dockerfile
CMD ["node", "app.js"]
# AND
CMD ["npm", "start"]
```

---

# Running commands in Dockerfile

RUN can be specified multiple times while CMD and ENTRYPOINT can only be specified once.

```Dockerfile
RUN npm install
```

Two possible syntaxes:

```Dockerfile
CMD ["node", "app.js"]
# OR
CMD node app.js
```

ENTRYPOINT example:

```Dockerfile
ENTRYPOINT ["node", "app.js"]
```

---

# RUN vs CMD vs ENTRYPOINT

**RUN**: Executes during the build phase to set up the image. Can be run multiple times.

**ENTRYPOINT**: Defines the main command to run when the container starts. You can pass flags when running the container.

**CMD**: Provides the default command to execute when starting a container. You can override `CMD` when running the container by adding `node another_app.js` after `docker run <image_name>` for example. 

You can combine the last two:

```Dockerfile
ENTRYPOINT ["node"]
CMD ["app.js"]
```

Which gives the freedom to do the following:

```bash
$ docker run --entrypoint node_runtime_latest <image_name>
$ docker run <image_name> another_app.js
```

---

# Docker hands-on meta slide

Since the `whoknows_variations` will show how to create `Dockerfile`s and `docker-compose.yml` files for Python. 

The in-class exercises will focus on Node.js. 

---

# Let's set up a Node.js project

```bash
$ mkdir 02._docker_node_project
$ cd 02._docker_node_project
$ mkdir node_project
$ cd node_project
$ npm init -y
$ npm install express
```

First we will set `type: module` in `package.json` to use ES6 modules.

Then set up the server in `app.js`. 

---

# Create the Dockerfile in `node_project`

```Dockerfile
FROM node

WORKDIR /usr/src/app

COPY package*.json ./

RUN npm install

COPY . .

EXPOSE 8080
CMD [ "node", "app.js" ]
```

---

# Build and run

Let's name the image `node_project`:

```bash
$ docker build -t <image_name> .
```

We want to map both the host port and the container port to `8080`


```bash
docker run -p <host_port>:<container_port> <image-name>
```

*Can you figure it out?*

---

# Build and run solution

Solution: 

```bash
$ docker build -t node_project .
$ docker run -p 8080:8080 node_project
```

Combined:
    
```bash
$ docker build -t node_project . && docker run -p 8080:8080 node_project
```


---

# Dockerfile create a user 

```Dockerfile
FROM node:14.16.0-alpine3.13

RUN addgroup app-user && adduser -S -G app-user appuser

USER appuser

WORKDIR /usr/src/app

COPY package*.json ./

RUN npm install

COPY . .

EXPOSE 8080
CMD [ "node", "app.js" ]
```

---

# Check user

Run it with an interactive shell:

```bash
$ docker build -t node_project .
$ docker run -it --rm node_project /bin/sh
```

See the user:

```bash
/app $ whoami
app-user
```

---

# Check who owns the files


Check who owns the files:

```bash
/app $ ls -l
```

<img src="./assets_dockerfile/created_user_ownership.png" alt="docker created user and file ownership" style="height: 10vh;">

`node_modules` is owned by `app-user` because `npm install` was run as `app-user`.

---

<div class="title-card">
    <h1>.dockerignore</h1>
</div>


---

# .dockerignore

<img src="./assets_docker/dockerignore_logo.png" alt="docker gitignore logo">

*What are files and folders to ignore?*

---

# `.dockerignore` possible template

```plaintext
**/.git
**/.gitignore
**/.vs
**/.vscode
**/*.*proj.user
**/*.dbmdl
**/*.jfm
**/bin
**/docker-compose*
**/node_modules
**/npm-debug.log
**/obj
**/secrets.dev.yaml
**/values.dev.yaml
```

Let's add it to the project.

---

<div class="title-card">
    <h1>Docker layers</h1>
</div>

---


# Docker layers

Each image consists of a layer. 

When you build an image, Docker creates a new layer for each instruction in the Dockerfile. 

When you change the Dockerfile and rebuild the image, only the layers that have changed are rebuilt.

Inspect the layers with:

```bash
$ docker history <image-name>
```

The bottom part are the layers of the base image.

---

# Docker layers optimization

When building an image, Docker will only execute instructions from top to bottom. But it only executes the instructions that have changed.

Otherwise it will reuse the layers from the cache.

This file is not optimized. *How can we use Docker's caching mechanism more efficiently?*

```Dockerfile
FROM node

WORKDIR /usr/src/app

COPY . .

RUN npm install

EXPOSE 8080

CMD [ "node", "app.js" ]
```

---

# Improved Dockerfile

If there is no change to `package.json` then there is no need to run `npm install` again.  

```Dockerfile
FROM node

WORKDIR /usr/src/app

COPY package*.json ./

RUN npm install

COPY . .

EXPOSE 8080

CMD [ "node", "app.js" ]
```

Note, that this is with only one dependency (Express). With more dependencies the difference could easily amount to a minute vs. less than a second. 

<img src="./assets_dockerfile/build_not_optimized.png" alt="dockerfile build not optimized" style="height: 2vh;">

<img src="./assets_dockerfile/build_optimized.png" alt="dockerfile build optimized" style="height: 2vh;">


</textarea>

<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>
    const slideshow = remark.create({
        source: document.getElementById('source').value
    });
</script>
</body>
</html>
